{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "ifaUIpOP6c2Z",
        "ztPxZxfasPlZ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Necessary Libraries"
      ],
      "metadata": {
        "id": "SxzXMag0OH_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
        "import string\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from IPython.utils.capture import capture_output\n",
        "from math import log2\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load nltk resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "print(\"Imported all necessary libraries successfully\")"
      ],
      "metadata": {
        "id": "skWrhkDnOPUB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373d4e60-361b-48f5-ec34-fb51130e6c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported all necessary libraries successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing (Cleaning & Preprocessing)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b0NW9s1POQij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_sentence_level(text, remove_stopwords=True, lemmatize=True, stem=False):\n",
        "    # Split text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "    processed_sentences = []\n",
        "\n",
        "    # Set up stop words, lemmatizer, and stemmer\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "    # Process each sentence\n",
        "    for sentence in sentences:\n",
        "        # Tokenize sentence\n",
        "        tokens = word_tokenize(sentence)\n",
        "        # Convert to lowercase and remove non-alphanumeric tokens i.e. punctiation\n",
        "        tokens = [token.lower() for token in tokens if token.isalnum()]\n",
        "        # Remove stopwords\n",
        "        if remove_stopwords:\n",
        "            tokens = [token for token in tokens if token not in stop_words]\n",
        "        # Lemmatize\n",
        "        if lemmatize:\n",
        "          # Since the lemmatizer as it's default pos is noun then the lemma of media is medium so it gets removed from the corupus\n",
        "          tokens = [lemmatizer.lemmatize(token) if token != 'media' else token for token in tokens]\n",
        "        # Stem\n",
        "        if stem:\n",
        "            tokens = [stemmer.stem(token) for token in tokens]\n",
        "        # Add the processed sentence\n",
        "        processed_sentences.append(tokens)\n",
        "\n",
        "    return processed_sentences\n"
      ],
      "metadata": {
        "id": "rsUIymoZOdJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "RCTPVtIutCrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Data"
      ],
      "metadata": {
        "id": "rBe5XUzttfeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "training_data_path = './data/Training-dataset.csv'\n",
        "training_data = pd.read_csv(training_data_path)\n",
        "\n",
        "# Apply preprocessing to each plot synopsis\n",
        "training_data['processed_plot_synopsis'] = training_data['plot_synopsis'].apply(preprocess_text_sentence_level, stem=False)\n",
        "\n",
        "# Flatten the list of processed synopses to feed into Word2Vec\n",
        "synopses = [synopsis for sublist in training_data['processed_plot_synopsis'].tolist() for synopsis in sublist]"
      ],
      "metadata": {
        "id": "YwzXIrEgV7OQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = [token for sublist in synopses for token in sublist]\n",
        "# Convert the list to a set to get unique tokens\n",
        "unique_tokens = set(all_tokens)\n",
        "# Return the number of unique tokens\n",
        "print(len(unique_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcmZfg-dEPlw",
        "outputId": "d7d1a9a7-1386-41dc-f41f-2f85559617ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation Data"
      ],
      "metadata": {
        "id": "j1OZIB15th9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the validation dataset, assuming no header in the CSV\n",
        "validation_dataset_path = './data/Task-1-validation-dataset.csv'\n",
        "validation_data = pd.read_csv(validation_dataset_path, header=None)"
      ],
      "metadata": {
        "id": "62kEuBNYtazx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Data"
      ],
      "metadata": {
        "id": "kiGJyAVbtlio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the testing dataset, assuming no header in the CSV\n",
        "testing_dataset_path = './data/Task-1-test-dataset1.csv'\n",
        "testing_data = pd.read_csv(testing_dataset_path, header=None)"
      ],
      "metadata": {
        "id": "X5JYklRHtnwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method A : PPMI"
      ],
      "metadata": {
        "id": "n2L5j2PE45ed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code used dictionaries instead of matrices due to the fact that there is not enough RAM in colab to accommodate such a sparse and big matrix of 80k x 80k. Hence to mitigate this dictionaries were used as they are much faster in retrieval time and would act in the same way as a matrix because each entry of the matrix is not stored in the dictionary."
      ],
      "metadata": {
        "id": "aepBUrEH8lzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_co_occurrence_dict(sentences, window_size=2, smoothness = 0):\n",
        "    # Tokenize and flatten the sentences into a list of words\n",
        "    words = [word for sentence in sentences for word in sentence]\n",
        "\n",
        "    # Count the unique words\n",
        "    vocab = set(words)\n",
        "    word_to_id = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "    # Initialize an co-occurrence dictionary with values smoothness\n",
        "    co_occurrence_dict = defaultdict(lambda : smoothness)\n",
        "\n",
        "    # Iterate over sentences with a progress bar\n",
        "    for sentence in tqdm(sentences, desc='Building Co-occurrence Dictionary'):\n",
        "        # For each word, consider 'window_size' words before and after as the context\n",
        "        for i, word in enumerate(sentence):\n",
        "            # Define the window range for the context\n",
        "            start = max(i - window_size, 0)\n",
        "            end = min(i + window_size + 1, len(sentence))\n",
        "            context = sentence[start:i] + sentence[i+1:end]  # Exclude the target word itself\n",
        "\n",
        "            # Increment counts in the dictionary for the target word and context word pair\n",
        "            target_id = word_to_id[word]\n",
        "            for context_word in context:\n",
        "                context_id = word_to_id[context_word]\n",
        "                if target_id != context_id:  # Optional: exclude self-co-occurrence\n",
        "                    co_occurrence_dict[(target_id, context_id)] += 1\n",
        "\n",
        "    return dict(co_occurrence_dict), word_to_id\n",
        "\n",
        "co_occurrence_dict, word_to_id = build_co_occurrence_dict(synopses, window_size=1, smoothness = 0)"
      ],
      "metadata": {
        "id": "MkNz-IFHAiwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ce58ad8-a25b-4576-eff8-e947d5869b82"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Co-occurrence Dictionary: 100%|██████████| 337763/337763 [01:28<00:00, 3826.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_ppmi(co_occurrence_dict, word_to_id, total_occurrences, word_freq, context_freq):\n",
        "    ppmi_dict = {}\n",
        "\n",
        "    # Iterate over each word pair in the co-occurrence dictionary\n",
        "    for (word_id, context_id), co_occurrence in tqdm(co_occurrence_dict.items(), desc=\"Calculating PPMI\"):\n",
        "        p_wc = co_occurrence / total_occurrences\n",
        "        p_w = word_freq[word_id] / total_occurrences\n",
        "        p_c = context_freq[context_id] / total_occurrences\n",
        "        ppmi = max(0, log2(p_wc / (p_w * p_c)) if p_wc > 0 else 0)\n",
        "        ppmi_dict[(word_id, context_id)] = ppmi\n",
        "\n",
        "    return ppmi_dict"
      ],
      "metadata": {
        "id": "5ya6UZwwB_9i"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate total_occurrences, word_freq, and context_freq from co_occurrence_dict\n",
        "total_occurrences = sum(co_occurrence_dict.values())\n",
        "vocab_size = len(word_to_id)\n",
        "word_freq = [0] * vocab_size\n",
        "context_freq = [0] * vocab_size\n",
        "\n",
        "# Accumulate word and context frequencies\n",
        "for (word_id, context_id), count in co_occurrence_dict.items():\n",
        "    word_freq[word_id] += count\n",
        "    context_freq[context_id] += count\n",
        "\n",
        "# Now calculate PPMI values\n",
        "ppmi_dict = calculate_ppmi(co_occurrence_dict, word_to_id, total_occurrences, word_freq, context_freq)"
      ],
      "metadata": {
        "id": "ZVyqHBKgBlcK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7910b2c-9161-45ea-c044-a7b1c9d99d4d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating PPMI: 100%|██████████| 3987350/3987350 [00:07<00:00, 564690.33it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_similarity_ppmi(word1, word2):\n",
        "  # Check if both words are in the vocabulary\n",
        "    if word1 not in word_to_id or word2 not in word_to_id:\n",
        "        print(f\"({word1}, {word2}) not found.\")\n",
        "        return 0.01\n",
        "    # Initialize vectors with zeros\n",
        "    vec1 = np.zeros(len(word_to_id))\n",
        "    vec2 = np.zeros(len(word_to_id))\n",
        "\n",
        "    # Populate the vectors with PPMI values from ppmi_dict\n",
        "    for (w1_id, context_id), ppmi_value in ppmi_dict.items():\n",
        "        if word_to_id[word1] == w1_id:\n",
        "            vec1[context_id] = ppmi_value\n",
        "    for (w2_id, context_id), ppmi_value in ppmi_dict.items():\n",
        "        if word_to_id[word2] == w2_id:\n",
        "            vec2[context_id] = ppmi_value\n",
        "\n",
        "    # Calculate and return the cosine similarity\n",
        "    similarity = cosine_similarity([vec1], [vec2])[0][0]\n",
        "    return similarity"
      ],
      "metadata": {
        "id": "2gALJ1Fo9jHB"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prediction_csv_ppmi(data, dataset):\n",
        "  # Drop the last column\n",
        "  prediction_data = data.copy()\n",
        "  prediction_data.drop(prediction_data.columns[1:], axis=1, inplace=True)\n",
        "\n",
        "  # Calculate similarity and add as a new column\n",
        "  prediction_data[1] = data.apply(lambda row: calculate_similarity_ppmi(row[1], row[2]), axis=1)\n",
        "  if dataset == 'validation':\n",
        "    # Save the new dataset to a CSV file\n",
        "    prediction_path = './data/10726993-Task1-method-a-validation.csv'\n",
        "    prediction_data.to_csv(prediction_path, index=False, header=False)\n",
        "  if dataset == 'testing':\n",
        "    # Save the new dataset to a CSV file\n",
        "    prediction_path = './data/10726993-Task1-method-a.csv'\n",
        "    prediction_data.to_csv(prediction_path, index=False, header=False)"
      ],
      "metadata": {
        "id": "YZbOkBHuEHng"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating CSVs"
      ],
      "metadata": {
        "id": "hox6FobyL0Th"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation"
      ],
      "metadata": {
        "id": "O_Hh2xd0L2rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_prediction_csv_ppmi(validation_data, \"validation\")"
      ],
      "metadata": {
        "id": "1v7C8N1BH8iJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de03664b-50bb-4d36-ed5e-dae9ad2c3c4d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware) not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "AG_0A9VSL3y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_prediction_csv_ppmi(testing_data, \"testing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnxry6Pmz1Nm",
        "outputId": "d82b6bf1-65e3-4992-a102-815c0b6ca93c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(keep, possess) not found.\n",
            "( war criminal, student) not found.\n",
            "( war criminal, jet) not found.\n",
            "(brutal murder, instructor) not found.\n",
            "(brutal murder, terrible) not found.\n",
            "(college graduate, teacher) not found.\n",
            "(college graduate, job) not found.\n",
            "(boy, teenage couple) not found.\n",
            "(cat, teenage couple) not found.\n",
            "(take, possess) not found.\n",
            "(journey, long distance) not found.\n",
            "(area, long distance) not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "ifaUIpOP6c2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ignore this as it was for testing purposes ( code may not work if you run it ) also it took 2hours so don't bother"
      ],
      "metadata": {
        "id": "HZtnqrapIAGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy():\n",
        "  with capture_output() as c:\n",
        "      %run task1_eval_script_student_version.py ./data/10726993-Task1-method-a-validation.csv ./data/Task-1-validation-dataset.csv\n",
        "      accuracy = c.stdout.splitlines()[-1]\n",
        "      accuracy = accuracy.split()[-1]\n",
        "      return float(accuracy)"
      ],
      "metadata": {
        "id": "geqUIldS6gJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for window in [1,2,3,4,5]:\n",
        "    for smooth_value in [0, 1, 2]:\n",
        "        # keep track of time\n",
        "        start = time.time()\n",
        "\n",
        "        co_occurrence_dict, word_to_id = build_co_occurrence_dict(synopses, window_size=window, smoothness = smooth_value)\n",
        "\n",
        "        total_occurrences = sum(co_occurrence_dict.values())\n",
        "        vocab_size = len(word_to_id)\n",
        "        word_freq = [0] * vocab_size\n",
        "        context_freq = [0] * vocab_size\n",
        "\n",
        "        # Accumulate word and context frequencies\n",
        "        for (word_id, context_id), count in co_occurrence_dict.items():\n",
        "            word_freq[word_id] += count\n",
        "            context_freq[context_id] += count\n",
        "\n",
        "        # Now calculate PPMI values\n",
        "        ppmi_dict = calculate_ppmi(co_occurrence_dict, word_to_id, total_occurrences, word_freq, context_freq)\n",
        "\n",
        "        create_prediction_csv_ppmi(validation_data)\n",
        "        end = time.time()\n",
        "\n",
        "        # Calculate accuracy score\n",
        "        accuracy = calculate_accuracy()\n",
        "        hyperparameter_entry = {\n",
        "            'window': window,\n",
        "            'smoothness': smooth_value,\n",
        "            'accuracy': np.round(accuracy, 2),\n",
        "            'time(s)': np.round(end-start, 2),\n",
        "        }\n",
        "        print(hyperparameter_entry)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ha6WoKec6n6M",
        "outputId": "18925c4a-b520-4aed-8484-6690b1beef1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Co-occurrence Dictionary: 100%|██████████| 337763/337763 [00:11<00:00, 29286.32it/s]\n",
            "Calculating PPMI: 100%|██████████| 3987350/3987350 [00:07<00:00, 508858.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware) not found.\n",
            "{'window': 1, 'smoothness': 0, 'accuracy': 0.6, 'time(s)': 271.03}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Co-occurrence Dictionary: 100%|██████████| 337763/337763 [00:10<00:00, 31715.18it/s]\n",
            "Calculating PPMI: 100%|██████████| 3987350/3987350 [00:06<00:00, 611375.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware) not found.\n",
            "{'window': 1, 'smoothness': 1, 'accuracy': 0.59, 'time(s)': 230.97}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Co-occurrence Dictionary: 100%|██████████| 337763/337763 [00:11<00:00, 28898.14it/s]\n",
            "Calculating PPMI: 100%|██████████| 3987350/3987350 [00:07<00:00, 506586.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware) not found.\n",
            "{'window': 1, 'smoothness': 2, 'accuracy': 0.58, 'time(s)': 231.71}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Co-occurrence Dictionary: 100%|██████████| 337763/337763 [00:17<00:00, 19621.99it/s]\n",
            "Calculating PPMI: 100%|██████████| 7240898/7240898 [00:14<00:00, 484943.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware) not found.\n",
            "{'window': 2, 'smoothness': 0, 'accuracy': 0.58, 'time(s)': 392.34}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Co-occurrence Dictionary: 100%|██████████| 337763/337763 [00:17<00:00, 19776.80it/s]\n",
            "Calculating PPMI: 100%|██████████| 7240898/7240898 [00:13<00:00, 553618.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware) not found.\n",
            "{'window': 2, 'smoothness': 1, 'accuracy': 0.58, 'time(s)': 389.91}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Co-occurrence Dictionary: 100%|██████████| 337763/337763 [00:18<00:00, 18515.07it/s]\n",
            "Calculating PPMI: 100%|██████████| 7240898/7240898 [00:13<00:00, 544398.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware) not found.\n",
            "{'window': 2, 'smoothness': 2, 'accuracy': 0.57, 'time(s)': 385.06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Co-occurrence Dictionary: 100%|██████████| 337763/337763 [00:23<00:00, 14632.08it/s]\n",
            "Calculating PPMI: 100%|██████████| 9864240/9864240 [00:16<00:00, 580271.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware) not found.\n",
            "{'window': 3, 'smoothness': 0, 'accuracy': 0.58, 'time(s)': 445.62}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Co-occurrence Dictionary: 100%|██████████| 337763/337763 [00:22<00:00, 14766.77it/s]\n",
            "Calculating PPMI: 100%|██████████| 9864240/9864240 [00:17<00:00, 569398.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware) not found.\n",
            "{'window': 3, 'smoothness': 1, 'accuracy': 0.57, 'time(s)': 448.6}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Co-occurrence Dictionary: 100%|██████████| 337763/337763 [00:22<00:00, 14772.74it/s]\n",
            "Calculating PPMI: 100%|██████████| 9864240/9864240 [00:17<00:00, 578789.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware) not found.\n",
            "{'window': 3, 'smoothness': 2, 'accuracy': 0.58, 'time(s)': 442.9}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Co-occurrence Dictionary: 100%|██████████| 337763/337763 [00:27<00:00, 12169.43it/s]\n",
            "Calculating PPMI: 100%|██████████| 12004420/12004420 [00:28<00:00, 424896.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware) not found.\n",
            "{'window': 4, 'smoothness': 0, 'accuracy': 0.56, 'time(s)': 570.04}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Co-occurrence Dictionary: 100%|██████████| 337763/337763 [00:29<00:00, 11518.48it/s]\n",
            "Calculating PPMI: 100%|██████████| 12004420/12004420 [00:23<00:00, 506542.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware) not found.\n",
            "{'window': 4, 'smoothness': 1, 'accuracy': 0.57, 'time(s)': 569.34}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Co-occurrence Dictionary: 100%|██████████| 337763/337763 [00:29<00:00, 11280.31it/s]\n",
            "Calculating PPMI: 100%|██████████| 12004420/12004420 [00:23<00:00, 515418.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware) not found.\n",
            "{'window': 4, 'smoothness': 2, 'accuracy': 0.57, 'time(s)': 574.95}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Co-occurrence Dictionary: 100%|██████████| 337763/337763 [00:32<00:00, 10461.31it/s]\n",
            "Calculating PPMI: 100%|██████████| 13760942/13760942 [00:27<00:00, 503135.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware) not found.\n",
            "{'window': 5, 'smoothness': 0, 'accuracy': 0.59, 'time(s)': 645.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Co-occurrence Dictionary: 100%|██████████| 337763/337763 [00:33<00:00, 10067.20it/s]\n",
            "Calculating PPMI: 100%|██████████| 13760942/13760942 [00:31<00:00, 433338.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware) not found.\n",
            "{'window': 5, 'smoothness': 1, 'accuracy': 0.59, 'time(s)': 646.87}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building Co-occurrence Dictionary: 100%|██████████| 337763/337763 [00:38<00:00, 8790.14it/s] \n",
            "Calculating PPMI: 100%|██████████| 13760942/13760942 [00:28<00:00, 480839.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware) not found.\n",
            "{'window': 5, 'smoothness': 2, 'accuracy': 0.59, 'time(s)': 666.75}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "wROOeEGxyWYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation"
      ],
      "metadata": {
        "id": "Y8AVUCfIIeMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run task1_eval_script_student_version.py ./data/10726993-Task1-method-a-validation.csv ./data/Task-1-validation-dataset.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFwaE8L_Gbni",
        "outputId": "af9903ae-adfb-4311-a37f-e042fbf98b3e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following simalarity scores may need checking:\n",
            "(absorb,learn) similarity score: 0.01178318673467594, gold ranking: 5.48\n",
            "(absorb,withdraw) similarity score: 0.012244545804659047, gold ranking: 2.97\n",
            "----------------------------\n",
            "(acquire,get) similarity score: 0.030680234530073035, gold ranking: 8.82\n",
            "(acquire,obtain) similarity score: 0.0742418186299178, gold ranking: 8.57\n",
            "----------------------------\n",
            "(arm,shoulder) similarity score: 0.07481171586764619, gold ranking: 4.85\n",
            "(arm,body) similarity score: 0.0870836099598039, gold ranking: 4.05\n",
            "----------------------------\n",
            "(arm,shoulder) similarity score: 0.07481171586764619, gold ranking: 4.85\n",
            "(arm,knee) similarity score: 0.08558231667302596, gold ranking: 2.75\n",
            "----------------------------\n",
            "(arm,shoulder) similarity score: 0.07481171586764619, gold ranking: 4.85\n",
            "(arm,neck) similarity score: 0.11294280832778489, gold ranking: 1.58\n",
            "----------------------------\n",
            "(arm,body) similarity score: 0.0870836099598039, gold ranking: 4.05\n",
            "(arm,neck) similarity score: 0.11294280832778489, gold ranking: 1.58\n",
            "----------------------------\n",
            "(arm,vein) similarity score: 0.028587445966036927, gold ranking: 3.65\n",
            "(arm,knee) similarity score: 0.08558231667302596, gold ranking: 2.75\n",
            "----------------------------\n",
            "(arm,vein) similarity score: 0.028587445966036927, gold ranking: 3.65\n",
            "(arm,neck) similarity score: 0.11294280832778489, gold ranking: 1.58\n",
            "----------------------------\n",
            "(arm,knee) similarity score: 0.08558231667302596, gold ranking: 2.75\n",
            "(arm,bone) similarity score: 0.04870453567092292, gold ranking: 3.83\n",
            "----------------------------\n",
            "(arm,knee) similarity score: 0.08558231667302596, gold ranking: 2.75\n",
            "(arm,neck) similarity score: 0.11294280832778489, gold ranking: 1.58\n",
            "----------------------------\n",
            "(arm,bone) similarity score: 0.04870453567092292, gold ranking: 3.83\n",
            "(arm,neck) similarity score: 0.11294280832778489, gold ranking: 1.58\n",
            "----------------------------\n",
            "(bath,trick) similarity score: 0.017442787762508294, gold ranking: 0.58\n",
            "(bath,wife) similarity score: 0.02572424712211184, gold ranking: 0.48\n",
            "----------------------------\n",
            "(bed,bedroom) similarity score: 0.09880863955777264, gold ranking: 3.4\n",
            "(bed,crib) similarity score: 0.041279470391483934, gold ranking: 7.3\n",
            "----------------------------\n",
            "(bed,blanket) similarity score: 0.06832561793020869, gold ranking: 3.02\n",
            "(bed,crib) similarity score: 0.041279470391483934, gold ranking: 7.3\n",
            "----------------------------\n",
            "(bed,crib) similarity score: 0.041279470391483934, gold ranking: 7.3\n",
            "(bed,hospital) similarity score: 0.05923682662931588, gold ranking: 0.92\n",
            "----------------------------\n",
            "(bed,crib) similarity score: 0.041279470391483934, gold ranking: 7.3\n",
            "(bed,chair) similarity score: 0.1284373887977967, gold ranking: 3.5\n",
            "----------------------------\n",
            "(belief,opinion) similarity score: 0.02973522092643876, gold ranking: 7.7\n",
            "(belief,impression) similarity score: 0.04397647082210866, gold ranking: 5.95\n",
            "----------------------------\n",
            "(belief,concept) similarity score: 0.012794570886794136, gold ranking: 5.08\n",
            "(belief,flower) similarity score: 0.0220302359015402, gold ranking: 0.4\n",
            "----------------------------\n",
            "(bird,turkey) similarity score: 0.015260787395341962, gold ranking: 6.58\n",
            "(bird,hen) similarity score: 0.009035598179171232, gold ranking: 7.03\n",
            "----------------------------\n",
            "(bird,turkey) similarity score: 0.015260787395341962, gold ranking: 6.58\n",
            "(bird,cock) similarity score: 0.009701782960511152, gold ranking: 7.1\n",
            "----------------------------\n",
            "(bone,jaw) similarity score: 0.043695550029874464, gold ranking: 4.17\n",
            "(bone,knee) similarity score: 0.0379703989406709, gold ranking: 4.17\n",
            "----------------------------\n",
            "(bone,jaw) similarity score: 0.043695550029874464, gold ranking: 4.17\n",
            "(bone,neck) similarity score: 0.045677022624280465, gold ranking: 2.53\n",
            "----------------------------\n",
            "(bone,jaw) similarity score: 0.043695550029874464, gold ranking: 4.17\n",
            "(bone,teeth) similarity score: 0.038453621866495945, gold ranking: 4.17\n",
            "----------------------------\n",
            "(bone,ankle) similarity score: 0.02692929197513007, gold ranking: 3.82\n",
            "(bone,neck) similarity score: 0.045677022624280465, gold ranking: 2.53\n",
            "----------------------------\n",
            "(bone,ankle) similarity score: 0.02692929197513007, gold ranking: 3.82\n",
            "(bone,elbow) similarity score: 0.035445986307611324, gold ranking: 3.78\n",
            "----------------------------\n",
            "(bone,knee) similarity score: 0.0379703989406709, gold ranking: 4.17\n",
            "(bone,neck) similarity score: 0.045677022624280465, gold ranking: 2.53\n",
            "----------------------------\n",
            "(bone,neck) similarity score: 0.045677022624280465, gold ranking: 2.53\n",
            "(bone,teeth) similarity score: 0.038453621866495945, gold ranking: 4.17\n",
            "----------------------------\n",
            "(bone,neck) similarity score: 0.045677022624280465, gold ranking: 2.53\n",
            "(bone,elbow) similarity score: 0.035445986307611324, gold ranking: 3.78\n",
            "----------------------------\n",
            "(book,literature) similarity score: 0.033226028362013854, gold ranking: 7.53\n",
            "(book,story) similarity score: 0.0837338917156088, gold ranking: 5.63\n",
            "----------------------------\n",
            "(book,literature) similarity score: 0.033226028362013854, gold ranking: 7.53\n",
            "(book,bible) similarity score: 0.08725688330049705, gold ranking: 5.0\n",
            "----------------------------\n",
            "(book,literature) similarity score: 0.033226028362013854, gold ranking: 7.53\n",
            "(book,information) similarity score: 0.05209973104387933, gold ranking: 5.0\n",
            "----------------------------\n",
            "(book,literature) similarity score: 0.033226028362013854, gold ranking: 7.53\n",
            "(book,article) similarity score: 0.10357849237186237, gold ranking: 5.43\n",
            "----------------------------\n",
            "(book,story) similarity score: 0.0837338917156088, gold ranking: 5.63\n",
            "(book,bible) similarity score: 0.08725688330049705, gold ranking: 5.0\n",
            "----------------------------\n",
            "(book,story) similarity score: 0.0837338917156088, gold ranking: 5.63\n",
            "(book,article) similarity score: 0.10357849237186237, gold ranking: 5.43\n",
            "----------------------------\n",
            "(book,bible) similarity score: 0.08725688330049705, gold ranking: 5.0\n",
            "(book,information) similarity score: 0.05209973104387933, gold ranking: 5.0\n",
            "----------------------------\n",
            "(book,essay) similarity score: 0.028766173906153103, gold ranking: 4.72\n",
            "(book,theme) similarity score: 0.030733271634330317, gold ranking: 2.58\n",
            "----------------------------\n",
            "(cat,lion) similarity score: 0.04463829868520598, gold ranking: 6.75\n",
            "(cat,pet) similarity score: 0.05339346697170764, gold ranking: 5.95\n",
            "----------------------------\n",
            "(cat,lion) similarity score: 0.04463829868520598, gold ranking: 6.75\n",
            "(cat,rabbit) similarity score: 0.06234253787759186, gold ranking: 2.37\n",
            "----------------------------\n",
            "(cat,pet) similarity score: 0.05339346697170764, gold ranking: 5.95\n",
            "(cat,rabbit) similarity score: 0.06234253787759186, gold ranking: 2.37\n",
            "----------------------------\n",
            "(clothes,drawer) similarity score: 0.04968970087241127, gold ranking: 3.02\n",
            "(clothes,fabric) similarity score: 0.023585435186345108, gold ranking: 5.87\n",
            "----------------------------\n",
            "(clothes,fabric) similarity score: 0.023585435186345108, gold ranking: 5.87\n",
            "(clothes,button) similarity score: 0.024174208552842656, gold ranking: 2.3\n",
            "----------------------------\n",
            "(clothes,fabric) similarity score: 0.023585435186345108, gold ranking: 5.87\n",
            "(clothes,coat) similarity score: 0.0999125775011288, gold ranking: 5.35\n",
            "----------------------------\n",
            "(clothes,fabric) similarity score: 0.023585435186345108, gold ranking: 5.87\n",
            "(clothes,jacket) similarity score: 0.07718880529407979, gold ranking: 5.15\n",
            "----------------------------\n",
            "(create,make) similarity score: 0.05768456573176514, gold ranking: 8.72\n",
            "(create,destroy) similarity score: 0.062759313425132, gold ranking: 0.63\n",
            "----------------------------\n",
            "(cup,cone) similarity score: 0.0004839043513656885, gold ranking: 3.17\n",
            "(cup,artifact) similarity score: 0.03314813649251749, gold ranking: 2.92\n",
            "----------------------------\n",
            "(cup,cone) similarity score: 0.0004839043513656885, gold ranking: 3.17\n",
            "(cup,entity) similarity score: 0.006463700718196396, gold ranking: 2.15\n",
            "----------------------------\n",
            "(cup,cone) similarity score: 0.0004839043513656885, gold ranking: 3.17\n",
            "(cup,article) similarity score: 0.011946184197285346, gold ranking: 2.4\n",
            "----------------------------\n",
            "(cup,cone) similarity score: 0.0004839043513656885, gold ranking: 3.17\n",
            "(cup,substance) similarity score: 0.010897392538040413, gold ranking: 1.92\n",
            "----------------------------\n",
            "(cup,jar) similarity score: 0.03365695631200182, gold ranking: 5.13\n",
            "(cup,tableware) similarity score: 0.01, gold ranking: 6.85\n",
            "----------------------------\n",
            "(cup,jar) similarity score: 0.03365695631200182, gold ranking: 5.13\n",
            "(cup,food) similarity score: 0.04673570959600671, gold ranking: 5.0\n",
            "----------------------------\n",
            "(cup,tableware) similarity score: 0.01, gold ranking: 6.85\n",
            "(cup,artifact) similarity score: 0.03314813649251749, gold ranking: 2.92\n",
            "----------------------------\n",
            "(cup,tableware) similarity score: 0.01, gold ranking: 6.85\n",
            "(cup,object) similarity score: 0.017971402625459754, gold ranking: 3.69\n",
            "----------------------------\n",
            "(cup,tableware) similarity score: 0.01, gold ranking: 6.85\n",
            "(cup,food) similarity score: 0.04673570959600671, gold ranking: 5.0\n",
            "----------------------------\n",
            "(cup,tableware) similarity score: 0.01, gold ranking: 6.85\n",
            "(cup,article) similarity score: 0.011946184197285346, gold ranking: 2.4\n",
            "----------------------------\n",
            "(cup,tableware) similarity score: 0.01, gold ranking: 6.85\n",
            "(cup,substance) similarity score: 0.010897392538040413, gold ranking: 1.92\n",
            "----------------------------\n",
            "(cup,artifact) similarity score: 0.03314813649251749, gold ranking: 2.92\n",
            "(cup,object) similarity score: 0.017971402625459754, gold ranking: 3.69\n",
            "----------------------------\n",
            "(cup,entity) similarity score: 0.006463700718196396, gold ranking: 2.15\n",
            "(cup,substance) similarity score: 0.010897392538040413, gold ranking: 1.92\n",
            "----------------------------\n",
            "(drink,car) similarity score: 0.037556844739304956, gold ranking: 3.04\n",
            "(drink,mother) similarity score: 0.043672209359621336, gold ranking: 2.65\n",
            "----------------------------\n",
            "(father,daughter) similarity score: 0.08486116912289501, gold ranking: 2.62\n",
            "(father,god) similarity score: 0.05096088808104869, gold ranking: 3.57\n",
            "----------------------------\n",
            "(guy,stud) similarity score: 0.01407763469212581, gold ranking: 5.83\n",
            "(guy,partner) similarity score: 0.03506706170066073, gold ranking: 3.57\n",
            "----------------------------\n",
            "(guy,stud) similarity score: 0.01407763469212581, gold ranking: 5.83\n",
            "(guy,girl) similarity score: 0.07134160695955488, gold ranking: 3.33\n",
            "----------------------------\n",
            "(guy,partner) similarity score: 0.03506706170066073, gold ranking: 3.57\n",
            "(guy,girl) similarity score: 0.07134160695955488, gold ranking: 3.33\n",
            "----------------------------\n",
            "(join,add) similarity score: 0.028126761079684533, gold ranking: 8.1\n",
            "(join,marry) similarity score: 0.0628858949049856, gold ranking: 5.35\n",
            "----------------------------\n",
            "(king,princess) similarity score: 0.03744828431912667, gold ranking: 3.27\n",
            "(king,rook) similarity score: 0.005971160165290662, gold ranking: 5.92\n",
            "----------------------------\n",
            "(lose,fail) similarity score: 0.04420728859154553, gold ranking: 7.33\n",
            "(lose,keep) similarity score: 0.04568879088899802, gold ranking: 1.05\n",
            "----------------------------\n",
            "(man,uncle) similarity score: 0.04120531726928679, gold ranking: 3.92\n",
            "(man,warrior) similarity score: 0.03694233793280738, gold ranking: 4.72\n",
            "----------------------------\n",
            "(man,uncle) similarity score: 0.04120531726928679, gold ranking: 3.92\n",
            "(man,governor) similarity score: 0.020300094977348034, gold ranking: 5.25\n",
            "----------------------------\n",
            "(man,father) similarity score: 0.06715081932071251, gold ranking: 4.83\n",
            "(man,child) similarity score: 0.07105135383629547, gold ranking: 4.13\n",
            "----------------------------\n",
            "(man,father) similarity score: 0.06715081932071251, gold ranking: 4.83\n",
            "(man,husband) similarity score: 0.055111617587617165, gold ranking: 5.32\n",
            "----------------------------\n",
            "(man,father) similarity score: 0.06715081932071251, gold ranking: 4.83\n",
            "(man,governor) similarity score: 0.020300094977348034, gold ranking: 5.25\n",
            "----------------------------\n",
            "(man,child) similarity score: 0.07105135383629547, gold ranking: 4.13\n",
            "(man,husband) similarity score: 0.055111617587617165, gold ranking: 5.32\n",
            "----------------------------\n",
            "(man,child) similarity score: 0.07105135383629547, gold ranking: 4.13\n",
            "(man,warrior) similarity score: 0.03694233793280738, gold ranking: 4.72\n",
            "----------------------------\n",
            "(man,child) similarity score: 0.07105135383629547, gold ranking: 4.13\n",
            "(man,governor) similarity score: 0.020300094977348034, gold ranking: 5.25\n",
            "----------------------------\n",
            "(man,victor) similarity score: 0.03977011571760391, gold ranking: 1.9\n",
            "(man,sentry) similarity score: 0.015069819514657124, gold ranking: 3.25\n",
            "----------------------------\n",
            "(man,victor) similarity score: 0.03977011571760391, gold ranking: 1.9\n",
            "(man,warrior) similarity score: 0.03694233793280738, gold ranking: 4.72\n",
            "----------------------------\n",
            "(man,victor) similarity score: 0.03977011571760391, gold ranking: 1.9\n",
            "(man,governor) similarity score: 0.020300094977348034, gold ranking: 5.25\n",
            "----------------------------\n",
            "(man,warrior) similarity score: 0.03694233793280738, gold ranking: 4.72\n",
            "(man,governor) similarity score: 0.020300094977348034, gold ranking: 5.25\n",
            "----------------------------\n",
            "(meat,bacon) similarity score: 0.014273449426400367, gold ranking: 5.8\n",
            "(meat,bread) similarity score: 0.05533909546938719, gold ranking: 1.67\n",
            "----------------------------\n",
            "(money,salary) similarity score: 0.03728808971583113, gold ranking: 7.88\n",
            "(money,diamond) similarity score: 0.08737160186500079, gold ranking: 3.42\n",
            "----------------------------\n",
            "(precedent,antecedent) similarity score: 0.0, gold ranking: 6.04\n",
            "(precedent,information) similarity score: 0.006059395349524646, gold ranking: 3.85\n",
            "----------------------------\n",
            "(precedent,antecedent) similarity score: 0.0, gold ranking: 6.04\n",
            "(precedent,cognition) similarity score: 0.0, gold ranking: 2.81\n",
            "----------------------------\n",
            "(precedent,antecedent) similarity score: 0.0, gold ranking: 6.04\n",
            "(precedent,group) similarity score: 0.0038051971529458853, gold ranking: 1.77\n",
            "----------------------------\n",
            "(precedent,cognition) similarity score: 0.0, gold ranking: 2.81\n",
            "(precedent,group) similarity score: 0.0038051971529458853, gold ranking: 1.77\n",
            "----------------------------\n",
            "(street,alley) similarity score: 0.08220595279436721, gold ranking: 5.48\n",
            "(street,place) similarity score: 0.05472843202638535, gold ranking: 6.44\n",
            "----------------------------\n",
            "(street,alley) similarity score: 0.08220595279436721, gold ranking: 5.48\n",
            "(street,avenue) similarity score: 0.028998033127108788, gold ranking: 8.88\n",
            "----------------------------\n",
            "(street,car) similarity score: 0.072122138281935, gold ranking: 2.38\n",
            "(street,place) similarity score: 0.05472843202638535, gold ranking: 6.44\n",
            "----------------------------\n",
            "(street,car) similarity score: 0.072122138281935, gold ranking: 2.38\n",
            "(street,avenue) similarity score: 0.028998033127108788, gold ranking: 8.88\n",
            "----------------------------\n",
            "(street,place) similarity score: 0.05472843202638535, gold ranking: 6.44\n",
            "(street,avenue) similarity score: 0.028998033127108788, gold ranking: 8.88\n",
            "----------------------------\n",
            "(take,obtain) similarity score: 0.027466875973290627, gold ranking: 7.1\n",
            "(take,receive) similarity score: 0.03252752821906762, gold ranking: 5.08\n",
            "----------------------------\n",
            "(take,obtain) similarity score: 0.027466875973290627, gold ranking: 7.1\n",
            "(take,carry) similarity score: 0.05580673620632201, gold ranking: 5.23\n",
            "----------------------------\n",
            "(take,obtain) similarity score: 0.027466875973290627, gold ranking: 7.1\n",
            "(take,deliver) similarity score: 0.03824493556696844, gold ranking: 4.37\n",
            "----------------------------\n",
            "(take,obtain) similarity score: 0.027466875973290627, gold ranking: 7.1\n",
            "(take,leave) similarity score: 0.08435274436395496, gold ranking: 2.47\n",
            "----------------------------\n",
            "(take,receive) similarity score: 0.03252752821906762, gold ranking: 5.08\n",
            "(take,deliver) similarity score: 0.03824493556696844, gold ranking: 4.37\n",
            "----------------------------\n",
            "(take,receive) similarity score: 0.03252752821906762, gold ranking: 5.08\n",
            "(take,leave) similarity score: 0.08435274436395496, gold ranking: 2.47\n",
            "----------------------------\n",
            "(take,carry) similarity score: 0.05580673620632201, gold ranking: 5.23\n",
            "(take,leave) similarity score: 0.08435274436395496, gold ranking: 2.47\n",
            "----------------------------\n",
            "(take,deliver) similarity score: 0.03824493556696844, gold ranking: 4.37\n",
            "(take,leave) similarity score: 0.08435274436395496, gold ranking: 2.47\n",
            "----------------------------\n",
            "(tiger,feline) similarity score: 0.014650759405180125, gold ranking: 8.0\n",
            "(tiger,animal) similarity score: 0.05588162750886888, gold ranking: 7.0\n",
            "----------------------------\n",
            "(tiger,carnivore) similarity score: 0.0, gold ranking: 7.08\n",
            "(tiger,mammal) similarity score: 0.0, gold ranking: 6.85\n",
            "----------------------------\n",
            "(tiger,carnivore) similarity score: 0.0, gold ranking: 7.08\n",
            "(tiger,animal) similarity score: 0.05588162750886888, gold ranking: 7.0\n",
            "----------------------------\n",
            "(tiger,carnivore) similarity score: 0.0, gold ranking: 7.08\n",
            "(tiger,organism) similarity score: 0.001148990034194691, gold ranking: 4.77\n",
            "----------------------------\n",
            "(tiger,carnivore) similarity score: 0.0, gold ranking: 7.08\n",
            "(tiger,fauna) similarity score: 0.0015270719837803316, gold ranking: 5.62\n",
            "----------------------------\n",
            "(tiger,mammal) similarity score: 0.0, gold ranking: 6.85\n",
            "(tiger,organism) similarity score: 0.001148990034194691, gold ranking: 4.77\n",
            "----------------------------\n",
            "(tiger,mammal) similarity score: 0.0, gold ranking: 6.85\n",
            "(tiger,fauna) similarity score: 0.0015270719837803316, gold ranking: 5.62\n",
            "----------------------------\n",
            "(happy,cheerful) similarity score: 0.030911332025936454, gold ranking: 9.55\n",
            "(happy,young) similarity score: 0.03289361423327024, gold ranking: 2.0\n",
            "----------------------------\n",
            "(car,highway) similarity score: 0.07024297957261952, gold ranking: 3.4\n",
            "(car,cab) similarity score: 0.06953623238178072, gold ranking: 7.42\n",
            "----------------------------\n",
            "(bad,immoral) similarity score: 0.016237627897630603, gold ranking: 7.62\n",
            "(bad,great) similarity score: 0.05095354440597728, gold ranking: 0.35\n",
            "----------------------------\n",
            "Accuracy: 0.6074074074074074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method B : Word2Vec"
      ],
      "metadata": {
        "id": "ztPxZxfasPlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Word2Vec model\n",
        "model = Word2Vec(synopses, vector_size=100, window=1, min_count=1, workers=1, sg=1)"
      ],
      "metadata": {
        "id": "CUNHLWAysVaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to calculate cosine similarity using Word2Vec\n",
        "def calculate_similarity(model, word1, word2):\n",
        "    if word1 in model.wv.key_to_index and word2 in model.wv.key_to_index:\n",
        "        return model.wv.similarity(word1, word2) ## uses cosine similarity internally\n",
        "    else:\n",
        "        # Returning 0.2 if one of the words is not in the vocabulary\n",
        "        print(f\"({word1}, {word2}) not found.\")\n",
        "        return 0.2"
      ],
      "metadata": {
        "id": "JvcwAi5Esega"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prediction_csv_w2v(model, data, dataset):\n",
        "  # Drop the last column\n",
        "  prediction_data = data.copy()\n",
        "  prediction_data.drop(prediction_data.columns[1:], axis=1, inplace=True)\n",
        "\n",
        "  # Calculate similarity and add as a new column\n",
        "  prediction_data[1] = data.apply(lambda row: calculate_similarity(model, row[1], row[2]), axis=1)\n",
        "\n",
        "  if dataset == 'validation':\n",
        "    # Save the new dataset to a CSV file\n",
        "    prediction_path = './data/10726993-Task1-method-b-validation.csv'\n",
        "    prediction_data.to_csv(prediction_path, index=False, header=False)\n",
        "  if dataset == 'testing':\n",
        "    # Save the new dataset to a CSV file\n",
        "    prediction_path = './data/10726993-Task1-method-b.csv'\n",
        "    prediction_data.to_csv(prediction_path, index=False, header=False)"
      ],
      "metadata": {
        "id": "pOzHrLr2shNS"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_prediction_csv_w2v(model, validation_data, \"validation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jGaV65-tG6j",
        "outputId": "04caaebb-c63f-4bde-b317-93d5bcf3165b"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware) not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_prediction_csv_w2v(model, testing_data, \"testing\")"
      ],
      "metadata": {
        "id": "i4GvaBIgI8D0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19849f90-e743-4774-a755-bf4dc4314542"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(keep, possess) not found.\n",
            "( war criminal, student) not found.\n",
            "( war criminal, jet) not found.\n",
            "(brutal murder, instructor) not found.\n",
            "(brutal murder, terrible) not found.\n",
            "(college graduate, teacher) not found.\n",
            "(college graduate, job) not found.\n",
            "(boy, teenage couple) not found.\n",
            "(cat, teenage couple) not found.\n",
            "(take, possess) not found.\n",
            "(journey, long distance) not found.\n",
            "(area, long distance) not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "2b13NLlvasta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ignore this as it was for testing purposes ( code may not work if you run it ) also it took 2hours so don't bother"
      ],
      "metadata": {
        "id": "iqT_AcoAUI9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy():\n",
        "  with capture_output() as c:\n",
        "      %run task1_eval_script_student_version.py ./data/10726993-Task1-method-b-validation.csv ./data/Task-1-validation-dataset.csv\n",
        "      accuracy = c.stdout.splitlines()[-1]\n",
        "      accuracy = accuracy.split()[-1]\n",
        "      return float(accuracy)"
      ],
      "metadata": {
        "id": "0cW8mC89dhsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epochs in tqdm.tqdm([5, 10, 30, 50]):\n",
        "    for vs in [100, 150, 200, 300]:\n",
        "        for window in [1,2,3,4,5]:\n",
        "            for sg in [0, 1]:\n",
        "                # keep track of time\n",
        "                start = time.time()\n",
        "\n",
        "                # Create word2vec model\n",
        "                w2v_model = Word2Vec(synopses, vector_size=vs, window=window, min_count=1, workers=4, sg=sg, epochs=epochs)\n",
        "\n",
        "                create_prediction_csv_w2v(w2v_model, validation_data, \"validation\")\n",
        "                end = time.time()\n",
        "\n",
        "                # Calculate accuracy score\n",
        "                accuracy = calculate_accuracy()\n",
        "                hyperparameter_entry = {\n",
        "                    'epochs': epochs,\n",
        "                    'vector size': vs,\n",
        "                    'window': window,\n",
        "                    'word2vec': \"cbow\" if sg == 0 else \"skip-gram\",\n",
        "                    'accuracy': accuracy,\n",
        "                    'time(s)': end-start\n",
        "                }\n",
        "                print(hyperparameter_entry)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "FFoOKjcia6c0",
        "outputId": "f0ac7622-6cff-4f2b-8df3-e3d246f08b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(cup, tableware)\n",
            "{'epochs': 5, 'vector_size': 100, 'window': 1, 'word2vec': 'cbow', 'accuracy': 0.64, 'time(s)': 41.94}\n",
            "(cup, tableware)\n",
            "{'epochs': 5, 'vector_size': 100, 'window': 1, 'word2vec': 'skip-gram', 'accuracy': 0.66, 'time(s)': 58.58}\n",
            "(cup, tableware)\n",
            "{'epochs': 5, 'vector_size': 100, 'window': 2, 'word2vec': 'cbow', 'accuracy': 0.61, 'time(s)': 42.22}\n",
            "(cup, tableware)\n",
            "{'epochs': 5, 'vector_size': 100, 'window': 2, 'word2vec': 'skip-gram', 'accuracy': 0.63, 'time(s)': 75.84}\n",
            "(cup, tableware)\n",
            "{'epochs': 5, 'vector_size': 100, 'window': 3, 'word2vec': 'cbow', 'accuracy': 0.6, 'time(s)': 43.19}\n",
            "(cup, tableware)\n",
            "{'epochs': 5, 'vector_size': 100, 'window': 3, 'word2vec': 'skip-gram', 'accuracy': 0.61, 'time(s)': 96.93}\n",
            "(cup, tableware)\n",
            "{'epochs': 5, 'vector_size': 100, 'window': 4, 'word2vec': 'cbow', 'accuracy': 0.6, 'time(s)': 44.54}\n",
            "(cup, tableware)\n",
            "{'epochs': 5, 'vector_size': 100, 'window': 4, 'word2vec': 'skip-gram', 'accuracy': 0.61, 'time(s)': 111.98}\n",
            "(cup, tableware)\n",
            "{'epochs': 5, 'vector_size': 100, 'window': 5, 'word2vec': 'cbow', 'accuracy': 0.62, 'time(s)': 45.73}\n",
            "(cup, tableware)\n",
            "{'epochs': 5, 'vector_size': 100, 'window': 5, 'word2vec': 'skip-gram', 'accuracy': 0.63, 'time(s)': 124.05}\n",
            "(cup, tableware)\n",
            "{'epochs': 5, 'vector_size': 150, 'window': 1, 'word2vec': 'cbow', 'accuracy': 0.63, 'time(s)': 53.83}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/4 [12:21<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubclass_\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: issubclass() arg 1 must be a class",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-fe9b8f36c912>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;31m# Create word2vec model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mw2v_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mcreate_prediction_datset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus_iterable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcorpus_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m             self.train(\n\u001b[1;32m    431\u001b[0m                 \u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0mreport_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'memory'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_retained_words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mprepare_vocab\u001b[0;34m(self, update, keep_raw_vocab, trim_rule, min_count, sample, dry_run)\u001b[0m\n\u001b[1;32m    740\u001b[0m                 \u001b[0mdownsample_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_vecattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sample_int'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_probability\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m32\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdry_run\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mset_vecattr\u001b[0;34m(self, key, attr, val)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \"\"\"\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallocate_vecattrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpandos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mallocate_vecattrs\u001b[0;34m(self, attrs, types)\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mprev_expando\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpandos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_expando\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m                 raise TypeError(\n\u001b[1;32m    325\u001b[0m                     \u001b[0;34mf\"Can't allocate type {t} for attribute {attr}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0marg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubclass_\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \"\"\"\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy when using vector_size = 300 & window = 1 is 0.6407407407407407 which is the highest until now.\n",
        "\n",
        "The default is vector_size = 100 window = 5 ?\n",
        "but I would say window = 1 works better than anything else\n",
        "I think hyperparameter tuning is required for word2vec even for other paramters that has not been used yet.\n",
        "\n",
        "using skip gram sg = 1, with vs 300, window = 1 gives Accuracy: 0.6481481481481481"
      ],
      "metadata": {
        "id": "qaAwl7w-BcYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "BGRUIsZSyLmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run task1_eval_script_student_version.py ./data/10726993-Task1-method-b-validation.csv ./data/Task-1-validation-dataset.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPoPOGDyyQ5i",
        "outputId": "a2e022f6-473f-4297-d364-57b6399bef70"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following simalarity scores may need checking:\n",
            "(absorb,learn) similarity score: 0.5250598788261414, gold ranking: 5.48\n",
            "(absorb,withdraw) similarity score: 0.7771555781364441, gold ranking: 2.97\n",
            "----------------------------\n",
            "(acquire,get) similarity score: 0.5366950035095215, gold ranking: 8.82\n",
            "(acquire,obtain) similarity score: 0.8529593348503113, gold ranking: 8.57\n",
            "----------------------------\n",
            "(apple,sauce) similarity score: 0.7262406349182129, gold ranking: 1.43\n",
            "(apple,lemon) similarity score: 0.716759204864502, gold ranking: 4.05\n",
            "----------------------------\n",
            "(arm,body) similarity score: 0.43532636761665344, gold ranking: 4.05\n",
            "(arm,vein) similarity score: 0.5751644372940063, gold ranking: 3.65\n",
            "----------------------------\n",
            "(arm,body) similarity score: 0.43532636761665344, gold ranking: 4.05\n",
            "(arm,knee) similarity score: 0.6686338186264038, gold ranking: 2.75\n",
            "----------------------------\n",
            "(arm,body) similarity score: 0.43532636761665344, gold ranking: 4.05\n",
            "(arm,bone) similarity score: 0.5654088854789734, gold ranking: 3.83\n",
            "----------------------------\n",
            "(arm,body) similarity score: 0.43532636761665344, gold ranking: 4.05\n",
            "(arm,neck) similarity score: 0.6511512398719788, gold ranking: 1.58\n",
            "----------------------------\n",
            "(arm,vein) similarity score: 0.5751644372940063, gold ranking: 3.65\n",
            "(arm,knee) similarity score: 0.6686338186264038, gold ranking: 2.75\n",
            "----------------------------\n",
            "(arm,vein) similarity score: 0.5751644372940063, gold ranking: 3.65\n",
            "(arm,bone) similarity score: 0.5654088854789734, gold ranking: 3.83\n",
            "----------------------------\n",
            "(arm,vein) similarity score: 0.5751644372940063, gold ranking: 3.65\n",
            "(arm,neck) similarity score: 0.6511512398719788, gold ranking: 1.58\n",
            "----------------------------\n",
            "(arm,knee) similarity score: 0.6686338186264038, gold ranking: 2.75\n",
            "(arm,bone) similarity score: 0.5654088854789734, gold ranking: 3.83\n",
            "----------------------------\n",
            "(arm,bone) similarity score: 0.5654088854789734, gold ranking: 3.83\n",
            "(arm,neck) similarity score: 0.6511512398719788, gold ranking: 1.58\n",
            "----------------------------\n",
            "(bath,trick) similarity score: 0.48425644636154175, gold ranking: 0.58\n",
            "(bath,balloon) similarity score: 0.7603395581245422, gold ranking: 0.4\n",
            "----------------------------\n",
            "(bath,wife) similarity score: 0.2782926857471466, gold ranking: 0.48\n",
            "(bath,balloon) similarity score: 0.7603395581245422, gold ranking: 0.4\n",
            "----------------------------\n",
            "(belief,opinion) similarity score: 0.5537186861038208, gold ranking: 7.7\n",
            "(belief,impression) similarity score: 0.60225510597229, gold ranking: 5.95\n",
            "----------------------------\n",
            "(bird,hen) similarity score: 0.6454828977584839, gold ranking: 7.03\n",
            "(bird,cock) similarity score: 0.6352508664131165, gold ranking: 7.1\n",
            "----------------------------\n",
            "(bone,ankle) similarity score: 0.7093297243118286, gold ranking: 3.82\n",
            "(bone,elbow) similarity score: 0.7310065031051636, gold ranking: 3.78\n",
            "----------------------------\n",
            "(book,literature) similarity score: 0.5972409248352051, gold ranking: 7.53\n",
            "(book,bible) similarity score: 0.76603764295578, gold ranking: 5.0\n",
            "----------------------------\n",
            "(book,literature) similarity score: 0.5972409248352051, gold ranking: 7.53\n",
            "(book,topic) similarity score: 0.6096881628036499, gold ranking: 2.07\n",
            "----------------------------\n",
            "(book,literature) similarity score: 0.5972409248352051, gold ranking: 7.53\n",
            "(book,essay) similarity score: 0.6555907726287842, gold ranking: 4.72\n",
            "----------------------------\n",
            "(book,literature) similarity score: 0.5972409248352051, gold ranking: 7.53\n",
            "(book,article) similarity score: 0.7064095139503479, gold ranking: 5.43\n",
            "----------------------------\n",
            "(book,story) similarity score: 0.5911418199539185, gold ranking: 5.63\n",
            "(book,bible) similarity score: 0.76603764295578, gold ranking: 5.0\n",
            "----------------------------\n",
            "(book,story) similarity score: 0.5911418199539185, gold ranking: 5.63\n",
            "(book,topic) similarity score: 0.6096881628036499, gold ranking: 2.07\n",
            "----------------------------\n",
            "(book,story) similarity score: 0.5911418199539185, gold ranking: 5.63\n",
            "(book,essay) similarity score: 0.6555907726287842, gold ranking: 4.72\n",
            "----------------------------\n",
            "(book,story) similarity score: 0.5911418199539185, gold ranking: 5.63\n",
            "(book,article) similarity score: 0.7064095139503479, gold ranking: 5.43\n",
            "----------------------------\n",
            "(book,bible) similarity score: 0.76603764295578, gold ranking: 5.0\n",
            "(book,information) similarity score: 0.47418659925460815, gold ranking: 5.0\n",
            "----------------------------\n",
            "(book,bible) similarity score: 0.76603764295578, gold ranking: 5.0\n",
            "(book,article) similarity score: 0.7064095139503479, gold ranking: 5.43\n",
            "----------------------------\n",
            "(book,topic) similarity score: 0.6096881628036499, gold ranking: 2.07\n",
            "(book,information) similarity score: 0.47418659925460815, gold ranking: 5.0\n",
            "----------------------------\n",
            "(book,topic) similarity score: 0.6096881628036499, gold ranking: 2.07\n",
            "(book,theme) similarity score: 0.4826580286026001, gold ranking: 2.58\n",
            "----------------------------\n",
            "(book,information) similarity score: 0.47418659925460815, gold ranking: 5.0\n",
            "(book,essay) similarity score: 0.6555907726287842, gold ranking: 4.72\n",
            "----------------------------\n",
            "(book,information) similarity score: 0.47418659925460815, gold ranking: 5.0\n",
            "(book,theme) similarity score: 0.4826580286026001, gold ranking: 2.58\n",
            "----------------------------\n",
            "(boy,brother) similarity score: 0.49985790252685547, gold ranking: 6.67\n",
            "(boy,soldier) similarity score: 0.5098208785057068, gold ranking: 2.15\n",
            "----------------------------\n",
            "(cat,lion) similarity score: 0.7486960291862488, gold ranking: 6.75\n",
            "(cat,rabbit) similarity score: 0.7817762494087219, gold ranking: 2.37\n",
            "----------------------------\n",
            "(cat,pet) similarity score: 0.672073483467102, gold ranking: 5.95\n",
            "(cat,rabbit) similarity score: 0.7817762494087219, gold ranking: 2.37\n",
            "----------------------------\n",
            "(clothes,drawer) similarity score: 0.6781582236289978, gold ranking: 3.02\n",
            "(clothes,fabric) similarity score: 0.6403462290763855, gold ranking: 5.87\n",
            "----------------------------\n",
            "(clothes,fabric) similarity score: 0.6403462290763855, gold ranking: 5.87\n",
            "(clothes,button) similarity score: 0.6555476784706116, gold ranking: 2.3\n",
            "----------------------------\n",
            "(clothes,fabric) similarity score: 0.6403462290763855, gold ranking: 5.87\n",
            "(clothes,coat) similarity score: 0.7581038475036621, gold ranking: 5.35\n",
            "----------------------------\n",
            "(clothes,fabric) similarity score: 0.6403462290763855, gold ranking: 5.87\n",
            "(clothes,jacket) similarity score: 0.7217522263526917, gold ranking: 5.15\n",
            "----------------------------\n",
            "(create,make) similarity score: 0.540721595287323, gold ranking: 8.72\n",
            "(create,destroy) similarity score: 0.6595066785812378, gold ranking: 0.63\n",
            "----------------------------\n",
            "(cup,cone) similarity score: 0.678672194480896, gold ranking: 3.17\n",
            "(cup,tableware) similarity score: 0.2, gold ranking: 6.85\n",
            "----------------------------\n",
            "(cup,cone) similarity score: 0.678672194480896, gold ranking: 3.17\n",
            "(cup,object) similarity score: 0.5782260298728943, gold ranking: 3.69\n",
            "----------------------------\n",
            "(cup,jar) similarity score: 0.7212538719177246, gold ranking: 5.13\n",
            "(cup,tableware) similarity score: 0.2, gold ranking: 6.85\n",
            "----------------------------\n",
            "(cup,tableware) similarity score: 0.2, gold ranking: 6.85\n",
            "(cup,artifact) similarity score: 0.5331212878227234, gold ranking: 2.92\n",
            "----------------------------\n",
            "(cup,tableware) similarity score: 0.2, gold ranking: 6.85\n",
            "(cup,object) similarity score: 0.5782260298728943, gold ranking: 3.69\n",
            "----------------------------\n",
            "(cup,tableware) similarity score: 0.2, gold ranking: 6.85\n",
            "(cup,entity) similarity score: 0.47142305970191956, gold ranking: 2.15\n",
            "----------------------------\n",
            "(cup,tableware) similarity score: 0.2, gold ranking: 6.85\n",
            "(cup,food) similarity score: 0.706606388092041, gold ranking: 5.0\n",
            "----------------------------\n",
            "(cup,tableware) similarity score: 0.2, gold ranking: 6.85\n",
            "(cup,article) similarity score: 0.42905059456825256, gold ranking: 2.4\n",
            "----------------------------\n",
            "(cup,tableware) similarity score: 0.2, gold ranking: 6.85\n",
            "(cup,substance) similarity score: 0.5750229954719543, gold ranking: 1.92\n",
            "----------------------------\n",
            "(cup,artifact) similarity score: 0.5331212878227234, gold ranking: 2.92\n",
            "(cup,substance) similarity score: 0.5750229954719543, gold ranking: 1.92\n",
            "----------------------------\n",
            "(cup,entity) similarity score: 0.47142305970191956, gold ranking: 2.15\n",
            "(cup,article) similarity score: 0.42905059456825256, gold ranking: 2.4\n",
            "----------------------------\n",
            "(cup,entity) similarity score: 0.47142305970191956, gold ranking: 2.15\n",
            "(cup,substance) similarity score: 0.5750229954719543, gold ranking: 1.92\n",
            "----------------------------\n",
            "(cup,article) similarity score: 0.42905059456825256, gold ranking: 2.4\n",
            "(cup,substance) similarity score: 0.5750229954719543, gold ranking: 1.92\n",
            "----------------------------\n",
            "(drink,car) similarity score: 0.3006085157394409, gold ranking: 3.04\n",
            "(drink,mother) similarity score: 0.3212544620037079, gold ranking: 2.65\n",
            "----------------------------\n",
            "(drink,car) similarity score: 0.3006085157394409, gold ranking: 3.04\n",
            "(drink,ear) similarity score: 0.47380998730659485, gold ranking: 1.31\n",
            "----------------------------\n",
            "(drink,mother) similarity score: 0.3212544620037079, gold ranking: 2.65\n",
            "(drink,ear) similarity score: 0.47380998730659485, gold ranking: 1.31\n",
            "----------------------------\n",
            "(guy,partner) similarity score: 0.4857332408428192, gold ranking: 3.57\n",
            "(guy,girl) similarity score: 0.6301043033599854, gold ranking: 3.33\n",
            "----------------------------\n",
            "(horse,mare) similarity score: 0.608364462852478, gold ranking: 8.33\n",
            "(horse,ox) similarity score: 0.6118590235710144, gold ranking: 3.02\n",
            "----------------------------\n",
            "(join,add) similarity score: 0.45929765701293945, gold ranking: 8.1\n",
            "(join,marry) similarity score: 0.5265001058578491, gold ranking: 5.35\n",
            "----------------------------\n",
            "(king,princess) similarity score: 0.5176997184753418, gold ranking: 3.27\n",
            "(king,rook) similarity score: 0.3949492275714874, gold ranking: 5.92\n",
            "----------------------------\n",
            "(king,rook) similarity score: 0.3949492275714874, gold ranking: 5.92\n",
            "(king,cabbage) similarity score: 0.42232590913772583, gold ranking: 0.23\n",
            "----------------------------\n",
            "(lose,keep) similarity score: 0.48948192596435547, gold ranking: 1.05\n",
            "(lose,get) similarity score: 0.5487314462661743, gold ranking: 0.77\n",
            "----------------------------\n",
            "(man,uncle) similarity score: 0.3974768817424774, gold ranking: 3.92\n",
            "(man,father) similarity score: 0.32457777857780457, gold ranking: 4.83\n",
            "----------------------------\n",
            "(man,uncle) similarity score: 0.3974768817424774, gold ranking: 3.92\n",
            "(man,child) similarity score: 0.32651787996292114, gold ranking: 4.13\n",
            "----------------------------\n",
            "(man,uncle) similarity score: 0.3974768817424774, gold ranking: 3.92\n",
            "(man,sentry) similarity score: 0.4600032567977905, gold ranking: 3.25\n",
            "----------------------------\n",
            "(man,uncle) similarity score: 0.3974768817424774, gold ranking: 3.92\n",
            "(man,governor) similarity score: 0.38543298840522766, gold ranking: 5.25\n",
            "----------------------------\n",
            "(man,father) similarity score: 0.32457777857780457, gold ranking: 4.83\n",
            "(man,child) similarity score: 0.32651787996292114, gold ranking: 4.13\n",
            "----------------------------\n",
            "(man,father) similarity score: 0.32457777857780457, gold ranking: 4.83\n",
            "(man,victor) similarity score: 0.33609846234321594, gold ranking: 1.9\n",
            "----------------------------\n",
            "(man,father) similarity score: 0.32457777857780457, gold ranking: 4.83\n",
            "(man,sentry) similarity score: 0.4600032567977905, gold ranking: 3.25\n",
            "----------------------------\n",
            "(man,father) similarity score: 0.32457777857780457, gold ranking: 4.83\n",
            "(man,warrior) similarity score: 0.46330419182777405, gold ranking: 4.72\n",
            "----------------------------\n",
            "(man,child) similarity score: 0.32651787996292114, gold ranking: 4.13\n",
            "(man,victor) similarity score: 0.33609846234321594, gold ranking: 1.9\n",
            "----------------------------\n",
            "(man,child) similarity score: 0.32651787996292114, gold ranking: 4.13\n",
            "(man,sentry) similarity score: 0.4600032567977905, gold ranking: 3.25\n",
            "----------------------------\n",
            "(man,sentry) similarity score: 0.4600032567977905, gold ranking: 3.25\n",
            "(man,husband) similarity score: 0.456269234418869, gold ranking: 5.32\n",
            "----------------------------\n",
            "(man,sentry) similarity score: 0.4600032567977905, gold ranking: 3.25\n",
            "(man,governor) similarity score: 0.38543298840522766, gold ranking: 5.25\n",
            "----------------------------\n",
            "(man,husband) similarity score: 0.456269234418869, gold ranking: 5.32\n",
            "(man,warrior) similarity score: 0.46330419182777405, gold ranking: 4.72\n",
            "----------------------------\n",
            "(man,warrior) similarity score: 0.46330419182777405, gold ranking: 4.72\n",
            "(man,governor) similarity score: 0.38543298840522766, gold ranking: 5.25\n",
            "----------------------------\n",
            "(meat,bacon) similarity score: 0.5188648104667664, gold ranking: 5.8\n",
            "(meat,bread) similarity score: 0.8605756759643555, gold ranking: 1.67\n",
            "----------------------------\n",
            "(money,salary) similarity score: 0.536822497844696, gold ranking: 7.88\n",
            "(money,diamond) similarity score: 0.6451868414878845, gold ranking: 3.42\n",
            "----------------------------\n",
            "(precedent,antecedent) similarity score: 0.9048285484313965, gold ranking: 6.04\n",
            "(precedent,cognition) similarity score: 0.922885537147522, gold ranking: 2.81\n",
            "----------------------------\n",
            "(precedent,information) similarity score: 0.48963263630867004, gold ranking: 3.85\n",
            "(precedent,cognition) similarity score: 0.922885537147522, gold ranking: 2.81\n",
            "----------------------------\n",
            "(street,alley) similarity score: 0.6200560927391052, gold ranking: 5.48\n",
            "(street,place) similarity score: 0.2915070056915283, gold ranking: 6.44\n",
            "----------------------------\n",
            "(street,alley) similarity score: 0.6200560927391052, gold ranking: 5.48\n",
            "(street,avenue) similarity score: 0.496873676776886, gold ranking: 8.88\n",
            "----------------------------\n",
            "(street,car) similarity score: 0.4455631673336029, gold ranking: 2.38\n",
            "(street,place) similarity score: 0.2915070056915283, gold ranking: 6.44\n",
            "----------------------------\n",
            "(take,obtain) similarity score: 0.4622758626937866, gold ranking: 7.1\n",
            "(take,carry) similarity score: 0.6457754969596863, gold ranking: 5.23\n",
            "----------------------------\n",
            "(take,obtain) similarity score: 0.4622758626937866, gold ranking: 7.1\n",
            "(take,deliver) similarity score: 0.5476505160331726, gold ranking: 4.37\n",
            "----------------------------\n",
            "(take,receive) similarity score: 0.4465475082397461, gold ranking: 5.08\n",
            "(take,deliver) similarity score: 0.5476505160331726, gold ranking: 4.37\n",
            "----------------------------\n",
            "(take,receive) similarity score: 0.4465475082397461, gold ranking: 5.08\n",
            "(take,leave) similarity score: 0.4556159973144531, gold ranking: 2.47\n",
            "----------------------------\n",
            "(tiger,carnivore) similarity score: 0.3810933530330658, gold ranking: 7.08\n",
            "(tiger,mammal) similarity score: 0.6589288711547852, gold ranking: 6.85\n",
            "----------------------------\n",
            "(tiger,carnivore) similarity score: 0.3810933530330658, gold ranking: 7.08\n",
            "(tiger,animal) similarity score: 0.6137110590934753, gold ranking: 7.0\n",
            "----------------------------\n",
            "(tiger,carnivore) similarity score: 0.3810933530330658, gold ranking: 7.08\n",
            "(tiger,organism) similarity score: 0.5529270172119141, gold ranking: 4.77\n",
            "----------------------------\n",
            "(tiger,carnivore) similarity score: 0.3810933530330658, gold ranking: 7.08\n",
            "(tiger,fauna) similarity score: 0.5890008211135864, gold ranking: 5.62\n",
            "----------------------------\n",
            "(tiger,mammal) similarity score: 0.6589288711547852, gold ranking: 6.85\n",
            "(tiger,animal) similarity score: 0.6137110590934753, gold ranking: 7.0\n",
            "----------------------------\n",
            "(accept,deliver) similarity score: 0.6288623213768005, gold ranking: 1.58\n",
            "(accept,believe) similarity score: 0.5904532670974731, gold ranking: 6.75\n",
            "----------------------------\n",
            "Accuracy: 0.6592592592592592\n"
          ]
        }
      ]
    }
  ]
}