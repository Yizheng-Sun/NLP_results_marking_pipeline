{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBXMfIHjXmFO"
      },
      "outputs": [],
      "source": [
        "#If any other libraries need installing, please add them here\n",
        "\n",
        "%pip install -U sentence-transformers\n",
        "# %pip install -U sklearn\n",
        "# %pip install -U gensim\n",
        "# %pip install -U nltk\n",
        "\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from gensim.models import Word2Vec, Phrases\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"./data/Training-dataset.csv\", usecols = ['plot_synopsis'])\n",
        "df_validation = pd.read_csv(\"./data/Task-1-validation-dataset.csv\", usecols = [0,1,2], names=[\"id\", \"word1\", \"word2\"])\n",
        "df_test = pd.read_csv(\"./data/Task-1-test-dataset1.csv\", usecols = [0,1,2], names=[\"id\", \"word1\", \"word2\"])\n",
        "\n",
        "\n",
        "#Gather term pairs from datasets to use for cosine similairty calculations\n",
        "validation_term_pairs = df_validation[[\"word1\", \"word2\"]].values\n",
        "test_term_pairs = df_test[[\"word1\", \"word2\"]].values"
      ],
      "metadata": {
        "id": "MwdFFpbkXt_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Word2Vec</h1>"
      ],
      "metadata": {
        "id": "eYvd0JwtyLKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function pre-processes documents via normalisation, tokenisation, punctuation removal, stop word removal and lemmatization\n",
        "\n",
        "def w2v_preprocess_text(text):\n",
        "\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    lemma = nltk.wordnet.WordNetLemmatizer()\n",
        "    tokens = [lemma.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "df_train['plot_synopsis_w2v_processed'] = df_train['plot_synopsis'].apply(w2v_preprocess_text)\n",
        "documents = df_train['plot_synopsis_w2v_processed'].tolist() #List of Lists where each inner list is a document of processed tokens"
      ],
      "metadata": {
        "id": "alCbaDDpyPtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Word2Vec Model with specified parameters\n",
        "\n",
        "vector_size = 200\n",
        "window_size = 1\n",
        "min_count = 1\n",
        "workers = 4\n",
        "epochs = 10\n",
        "\n",
        "w2v_model = Word2Vec(sentences=documents,\n",
        "                     vector_size=vector_size,\n",
        "                     window=window_size,\n",
        "                     min_count=min_count,\n",
        "                     workers=workers,\n",
        "                     epochs=epochs)"
      ],
      "metadata": {
        "id": "dIraBYR6zoWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculates the cosine similairty for each term pair using Word2Vec model\n",
        "\n",
        "def w2v_cosine_similarity(term1, term2, model):\n",
        "\n",
        "  words = list(model.wv.index_to_key)\n",
        "  if term1 in words and term2 in words:\n",
        "    return model.wv.similarity(term1, term2)\n",
        "  else:\n",
        "    return 0.5 #if either word isn't found in the model, return a similairty score of 0.5\n",
        "\n",
        "\n",
        "w2v_val_similarity = []\n",
        "for x in range (len(df_validation)):\n",
        "  w2v_val_similarity.append(w2v_cosine_similarity(validation_term_pairs[x][0], validation_term_pairs[x][1], w2v_model))\n",
        "\n",
        "w2v_test_similarity = []\n",
        "for x in range (len(df_test)):\n",
        "  w2v_test_similarity.append(w2v_cosine_similarity(test_term_pairs[x][0], test_term_pairs[x][1], w2v_model))\n"
      ],
      "metadata": {
        "id": "7z4miUBR05Aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creates CSV files from the validation and test results\n",
        "\n",
        "df_w2v_validation = pd.DataFrame({\n",
        "    'id': df_validation['id'],\n",
        "    'similarity': w2v_val_similarity\n",
        "})\n",
        "\n",
        "df_w2v_validation.to_csv(\"10560407-Task1-method-b-validation.csv\", index=False, header=False)\n",
        "\n",
        "\n",
        "df_w2v_test = pd.DataFrame({\n",
        "    'id': df_test['id'],\n",
        "    'similarity': w2v_test_similarity\n",
        "})\n",
        "\n",
        "df_w2v_test.to_csv(\"10560407-Task1-method-b.csv\", index=False, header=False)"
      ],
      "metadata": {
        "id": "KKP1IAMevGZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " <h1>RoBERTa</h1>"
      ],
      "metadata": {
        "id": "iHwAYdEByXgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roberta_model = SentenceTransformer('sentence-transformers/all-roberta-large-v1')"
      ],
      "metadata": {
        "id": "OHhr7ssz3ExK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculates the cosine similairty for each term pair using RoBERTa model\n",
        "\n",
        "def roberta_cosine_similarity(word1, word2, model):\n",
        "    vec1 = model.encode(word1).reshape(1,-1)\n",
        "    vec2 = model.encode(word2).reshape(1,-1)\n",
        "    similarity = cosine_similarity(vec1, vec2)[0][0]\n",
        "    return similarity\n",
        "\n",
        "roberta_val_similarity = []\n",
        "for x in range (len(df_validation)):\n",
        "  roberta_val_similarity.append(roberta_cosine_similarity(validation_term_pairs[x][0], validation_term_pairs[x][1], roberta_model))#\n",
        "\n",
        "roberta_test_similarity = []\n",
        "for x in range (len(df_test)):\n",
        "  roberta_test_similarity.append(roberta_cosine_similarity(test_term_pairs[x][0], test_term_pairs[x][1], roberta_model))"
      ],
      "metadata": {
        "id": "rSMoNbSR5Ylr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creates CSV files from the validation and test results\n",
        "\n",
        "df_roberta_validation = pd.DataFrame({\n",
        "    'id': df_validation['id'],\n",
        "    'similarity': roberta_val_similarity\n",
        "})\n",
        "\n",
        "df_roberta_validation.to_csv(\"10560407-Task1-method-c-validation.csv\", index=False, header=False)\n",
        "\n",
        "df_roberta_validation = pd.DataFrame({\n",
        "    'id': df_test['id'],\n",
        "    'similarity': roberta_test_similarity\n",
        "})\n",
        "\n",
        "df_roberta_validation.to_csv(\"10560407-Task1-method-c.csv\", index=False, header=False)"
      ],
      "metadata": {
        "id": "KaKk8PRXYxhq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}